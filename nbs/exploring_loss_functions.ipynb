{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "config = namedtuple('config', ['height', 'width'])\n",
    "config.height = 256\n",
    "config.width = 256\n",
    "config.batch_size=8\n",
    "config.num_epochs=1\n",
    "val_dir = 'test'\n",
    "train_dir = 'train'\n",
    "img_dir = 'images'\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open('/home/ubuntu/colorizer-applied-dl/test/amazing-beautiful-beauty-blue.jpg').resize((config.width, config.height))\n",
    "color_image = np.expand_dims(np.array(img), axis=0)\n",
    "bw_image = np.expand_dims(np.array(img.convert('L')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_rebalancing_segments(y_true, y_pred):\n",
    "    y_pred_clipped = K.clip(y_pred, K.epsilon(), None)\n",
    "\n",
    "    img_height = y_true.shape[1]\n",
    "    img_width = y_true.shape[2]\n",
    "\n",
    "    loss = -K.sum(y_true * K.log(y_pred_clipped), axis = 3)\n",
    "\n",
    "    bin_indices = K.argmax(y_true, axis = 3)\n",
    "    weights = K.gather(reference = AB_BIN_WEIGHTS, indices = bin_indices)\n",
    "\n",
    "    loss = RZHANG_LOSS_WEIGHT * K.sum(loss * weights)\n",
    "\n",
    "    loss += K.sum((y_pred[:, :-1, :, :] - y_pred[:, 1:, :, :]) ** 2)\n",
    "    loss += K.sum((y_pred[:, :, :-1, :] - y_pred[:, :, 1:, :]) ** 2)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.convert_to_tensor(color_image, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clipped = K.clip(y_pred, K.epsilon(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'clip_by_value_1:0' shape=(1, 256, 256, 3) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.convert_to_tensor(np.array(Image.open('/home/ubuntu/colorizer-applied-dl/test/art-creative-flowers-244497.jpg').resize((config.width, config.height))), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -K.sum(y_true * K.log(y_pred_clipped), axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(256), Dimension(256), Dimension(3)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
